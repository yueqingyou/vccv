<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="HandheldFriendly" content="True"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5"><meta name="theme-color" content="#000000"><link rel="manifest" href="/manifest.json"><script src="/sw-register.js"></script><meta name="description" content="How a non-root user can install a newer version of the transformers suite without being able to change the version of the installed cuda driver."><meta property="og:type" content="article"><meta property="og:title" content="Non-Root Installation of CUDA NLP by Conda"><meta property="og:url" content="https://vccv.cc/en/article/cuda-conda-nlp.html"><meta property="og:site_name" content="Yuesir"><meta property="og:description" content="How a non-root user can install a newer version of the transformers suite without being able to change the version of the installed cuda driver."><meta property="og:locale" content="en_US"><meta property="og:image" content="https://vccv.cc/en/article/cuda-conda-nlp/image-20240315144020525.png"><meta property="og:image" content="https://vccv.cc/en/article/cuda-conda-nlp/image-20240315144208260.png"><meta property="article:published_time" content="2024-03-10T08:13:14.000Z"><meta property="article:modified_time" content="2024-03-10T08:13:14.000Z"><meta property="article:author" content="Yuesir"><meta property="article:tag" content="conda"><meta property="article:tag" content="nvidia"><meta property="article:tag" content="cuda"><meta property="article:tag" content="transformers"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://vccv.cc/en/article/cuda-conda-nlp/image-20240315144020525.png"><link rel="shortcut icon" href="/en/images/favicon.ico"><link rel="icon" type="image/png" href="/en/images/favicon-192x192.png" sizes="192x192"><link rel="apple-touch-icon" sizes="180x180" href="/en/images/apple-touch-icon.png"><title>Non-Root Installation of CUDA NLP by Conda｜Yuesir</title><link rel="stylesheet" href="/en/css/style.css"><link rel="stylesheet" href="/en/css/style-dark.css"><script src="/en/js/switch.js"></script><link rel="stylesheet" href="/en/css/fancybox.css"><meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/en/atom.xml" title="Yuesir" type="application/atom+xml">
</head><body class="max-width mx-auto px3 ltr"><div id="header-post"><a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a> <span id="menu"><span id="nav"><ul><li><a href="/en">Home</a></li><li><a href="/en/tags">Tag</a></li><li><a href="/en/search">Search</a></li><li><a href="/en/tools">Tool</a></li><li><a href="/en/about">About</a></li></ul></span><br><span id="actions"><ul><li><a class="icon" aria-label="Previous post" href="/en/article/llm-transformers.html"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover='$("#i-prev").toggle()' onmouseout='$("#i-prev").toggle()'></i></a></li><li><a class="icon" aria-label="Next post" href="/en/article/switch-xcode-theos.html"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover='$("#i-next").toggle()' onmouseout='$("#i-next").toggle()'></i></a></li><li><a class="icon" aria-label="Back to top" href="#" onclick='$("html, body").animate({scrollTop:0},"fast")'><i class="fas fa-chevron-up" aria-hidden="true" onmouseover='$("#i-top").toggle()' onmouseout='$("#i-top").toggle()'></i></a></li><li><a class="icon" aria-label="Switch theme"><i class="fas fa-lightbulb" aria-hidden="true" onmouseover='$("#i-switch").toggle()' onmouseout='$("#i-switch").toggle()' onclick="switchNightMode()"></i></a></li><li><a class="icon" aria-label="Back to home" href="/en/"><i class="fas fa-home" aria-hidden="true" onmouseover='$("#i-home").toggle()' onmouseout='$("#i-home").toggle()'></i></a></li></ul><span id="i-prev" class="info" style="display:none">Previous post</span> <span id="i-next" class="info" style="display:none">Next post</span> <span id="i-top" class="info" style="display:none">Back to top</span> <span id="i-switch" class="info" style="display:none">Switch theme</span> <span id="i-home" class="info" style="display:none">Back to home</span></span><br><div id="toc"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#CUDA-driver"><span class="toc-number">1.</span> <span class="toc-text">CUDA driver</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Conda"><span class="toc-number">2.</span> <span class="toc-text">Conda</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pytorch"><span class="toc-number">3.</span> <span class="toc-text">Pytorch</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CUDA"><span class="toc-number">4.</span> <span class="toc-text">CUDA</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Cuda-installed-using-conda"><span class="toc-number">4.1.</span> <span class="toc-text">Cuda installed using conda</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Extra"><span class="toc-number">5.</span> <span class="toc-text">Extra</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#gcc-clang-g-clang"><span class="toc-number">5.1.</span> <span class="toc-text">gcc clang g++ clang++</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#xformers"><span class="toc-number">5.2.</span> <span class="toc-text">xformers</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#transformers-amp-datasets-amp-accelerate"><span class="toc-number">5.3.</span> <span class="toc-text">transformers &amp; datasets &amp; accelerate</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Reference"><span class="toc-number">6.</span> <span class="toc-text">Reference</span></a></li></ol></div></span></div><div class="content index py4"><article class="post" itemscope itemtype="http://schema.org/BlogPosting"><header><a href="javascript:void(0);" onclick="switchNightMode()"><h1 class="posttitle" itemprop="name headline">Non-Root Installation of CUDA NLP by Conda</h1></a><div class="meta"><div class="postdate">Posted: <time datetime="2024-03-10T08:13:14.000Z" itemprop="datePublished">2024-03-10</time> (Updated: <time datetime="2024-03-10T08:13:14.000Z" itemprop="dateModified">2024-03-10</time>)</div><div class="article-category"><i class="fas fa-archive"></i> <a class="category-link" href="/en/categories/linux/">linux</a> › <a class="category-link" href="/en/categories/linux/technique/">technique</a></div><div class="article-tag"><i class="fas fa-tag"></i> <a class="tag-link-link" href="/en/tags/conda/" rel="tag">conda</a>, <a class="tag-link-link" href="/en/tags/cuda/" rel="tag">cuda</a>, <a class="tag-link-link" href="/en/tags/nvidia/" rel="tag">nvidia</a>, <a class="tag-link-link" href="/en/tags/transformers/" rel="tag">transformers</a></div></div></header><div class="content" itemprop="articleBody"><p>Non-ROOT users configure a remote CUDA server for a deep learning environment, below is an example of Pytorch.</p><h2 id="CUDA-driver"><a href="#CUDA-driver" class="headerlink" title="CUDA driver"></a>CUDA driver</h2><p>Check the version of CUDA already installed on the server:</p><div class="highlight-wrap" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvcc -V</span><br></pre></td></tr></table></figure></div><p>Showing version 11.4 here, but it doesn’t matter. Next to check the driver version, this relates to the latest CUDA version that we can install in the conda virtual environment.</p><div class="highlight-wrap" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi</span><br><span class="line"></span><br><span class="line"><span class="comment">### Output</span></span><br><span class="line"><span class="comment">### Driver Version: 535.129.03   CUDA Version: 12.2</span></span><br></pre></td></tr></table></figure></div><blockquote><p>Tips:</p><p>The CUDA Version shown here is 12.2, which is actually the latest CUDA version that the CUDA driver installed on the server supports to install, which means that the highest CUDA version we can install next is 12.2, and the CUDA version that has already been installed on this machine is 11.4.</p><p>Because we are a NON-ROOT user, we can’t change the <u>installed driver version</u>, but we can install the new CUDA version through the Conda virtual environment.</p></blockquote><h2 id="Conda"><a href="#Conda" class="headerlink" title="Conda"></a>Conda</h2><p>When configuring python-related environments for non-root users, I extremely recommend using the conda package manager for dependency management (in fact, it’s also recommended for those using R).</p><p>I’m installing the miniconda version here (the minimized version), but you can also install anaconda (the full version).</p><p>The blog has been written about <a href="https://vccv.cc/en/article/conda-r-jupyter.html">related content</a> before.</p><div class="highlight-wrap" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># I installed the environment with python 3.10</span></span><br><span class="line">conda create -n torch python=3.10</span><br><span class="line">conda activate torch</span><br></pre></td></tr></table></figure></div><h2 id="Pytorch"><a href="#Pytorch" class="headerlink" title="Pytorch"></a>Pytorch</h2><p>You can check the Pytorch history release at <a target="_blank" rel="noopener" href="https://pytorch.org/get-started/previous-versions/">Pytorch History Release</a> and combine it with your own needs (e.g., [Colossal-AI](https:// colossalai.org/zh-Hans/docs/get_started/installation/) requires PyTorch &gt;= 1.11 and PyTorch &lt;= 2.1). I ended up with pytorch==2.1.0 and CUDA==11.8.</p><div class="highlight-wrap" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># CUDA 11.8</span></span><br><span class="line"><span class="comment"># Less than the maximum supported driver version 12.2 but more than the installed CUDA version 11.4</span></span><br><span class="line"><span class="comment"># Try not to jump to a bigger version</span></span><br><span class="line"><span class="comment"># For example, if I have 11.4 installed on my machine, then I would install it with cuda=11.8. Does it seem to be a problem to install 12.1?</span></span><br><span class="line">conda install pytorch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 pytorch-cuda=11.8 -c pytorch -c nvidia</span><br></pre></td></tr></table></figure></div><blockquote><p>Thinking:</p><p>As for why pytorch doesn’t redistribute for some cuda versions, in this <a target="_blank" rel="noopener" href="https://github.com/pytorch/pytorch/issues/75992">issue</a> one of pytorch’s developers explains that pytorch-cuda113 can be used on cuda114 This simply means that there is no need to re-release it, and that the 113 version can be used for the 114 version.</p><p><a data-fancybox="gallery" data-src="cuda-conda-nlp/image-20240315144020525.webp" data-caption="pytorch-cuda"><picture><source srcset="cuda-conda-nlp/image-20240315144020525.webp" type="image/webp"><img src="cuda-conda-nlp/image-20240315144020525.png" alt="pytorch-cuda"></picture></a></p></blockquote><p>Check availability</p><div class="highlight-wrap" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">(torch) [username/pwd]$ python</span><br><span class="line">Python 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0] on linux</span><br><span class="line">Type <span class="string">&quot;help&quot;</span>, <span class="string">&quot;copyright&quot;</span>, <span class="string">&quot;credits&quot;</span> or <span class="string">&quot;license&quot;</span> <span class="keyword">for</span> more information.</span><br><span class="line">&gt;&gt;&gt; import torch</span><br><span class="line">&gt;&gt;&gt; torch.cuda.is_available()</span><br><span class="line">True</span><br><span class="line">&gt;&gt;&gt; <span class="built_in">exit</span>()</span><br></pre></td></tr></table></figure></div><h2 id="CUDA"><a href="#CUDA" class="headerlink" title="CUDA"></a>CUDA</h2><p>At <a target="_blank" rel="noopener" href="https://anaconda.org/nvidia/cuda">Nvidia-Cuda</a> look for the CUDA version corresponding to the installed Pytorch, in my case 11.8.</p><div class="highlight-wrap" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># In nvidia, this channel doesn&#x27;t even show a progress bar when downloading packages.</span></span><br><span class="line"><span class="comment"># It will only show 0% or 100%, but the download speed is fine, it&#x27;s not walled off, just wait patiently.</span></span><br><span class="line">conda install nvidia/label/cuda-11.8.0::cuda</span><br></pre></td></tr></table></figure></div><p>At this point, enter the <code>nvcc -V</code> command to find that the installed version is now 11.8.</p><p><a data-fancybox="gallery" data-src="cuda-conda-nlp/image-20240315144208260.webp" data-caption="nvcc -V"><picture><source srcset="cuda-conda-nlp/image-20240315144208260.webp" type="image/webp"><img src="cuda-conda-nlp/image-20240315144208260.png" alt="nvcc -V"></picture></a></p><h3 id="Cuda-installed-using-conda"><a href="#Cuda-installed-using-conda" class="headerlink" title="Cuda installed using conda"></a>Cuda installed using conda</h3><div class="highlight-wrap" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This prevents programs that cannot find the CUDA (11.8) installed by conda from using the CUDA (11.4) that comes with the system.</span></span><br><span class="line"><span class="built_in">export</span> CUDA_HOME=<span class="variable">$CONDA_PREFIX</span></span><br></pre></td></tr></table></figure></div><h2 id="Extra"><a href="#Extra" class="headerlink" title="Extra"></a>Extra</h2><h3 id="gcc-clang-g-clang"><a href="#gcc-clang-g-clang" class="headerlink" title="gcc clang g++ clang++"></a>gcc clang g++ clang++</h3><div class="highlight-wrap" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># The server comes with a version of gcc that is too low and doesn&#x27;t even support g++. Use conda to install it and it works straight away.</span></span><br><span class="line">conda install -c conda-forge cxx-compiler</span><br></pre></td></tr></table></figure></div><h3 id="xformers"><a href="#xformers" class="headerlink" title="xformers"></a>xformers</h3><div class="highlight-wrap" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Official repository suggested commands</span></span><br><span class="line">conda install xformers -c xformers</span><br><span class="line"></span><br><span class="line"><span class="comment"># Be sure to double-check the package change log before confirming the installation.</span></span><br><span class="line"><span class="comment"># There is a chance that it could replace an installed version of pytorch, so don&#x27;t install it.</span></span><br><span class="line"><span class="comment"># Try adding -c nvidia -c pytorch and you should be fine.</span></span><br><span class="line">conda install xformers -c xformers -c nvidia -c pytorch</span><br></pre></td></tr></table></figure></div><h3 id="transformers-amp-datasets-amp-accelerate"><a href="#transformers-amp-datasets-amp-accelerate" class="headerlink" title="transformers &amp; datasets &amp; accelerate"></a>transformers &amp; datasets &amp; accelerate</h3><div class="highlight-wrap" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Installation with conda may not be the latest version</span></span><br><span class="line">pip install transformers datasets accelerate -U</span><br></pre></td></tr></table></figure></div><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a target="_blank" rel="noopener" href="https://anaconda.org/nvidia/cuda">Nvidia-Cuda</a></p><p><a target="_blank" rel="noopener" href="https://pytorch.org/get-started/previous-versions/">Pytorch History Release</a></p><p><a target="_blank" rel="noopener" href="https://github.com/pytorch/pytorch/issues/75992">Pytorch Github Issue</a></p><div id="copyright"><style>#easter-egg{border:0;padding:10px 0;position:relative}#easter-egg::before{font-family:"Font Awesome 5 Free";font-weight:900;content:"Page Over \f1b0  Thank You";position:absolute;padding:0 10px;line-height:1px;white-space:nowrap;left:50%;transform:translateX(-50%)}</style><hr id="easter-egg"><blockquote style="padding:0"><p>Author: Yuesir</p><p>Link: <a href="/en/article/cuda-conda-nlp.html" target="_blank" title="Non-Root Installation of CUDA NLP by Conda">https://vccv.cc/en/article/cuda-conda-nlp.html</a></p><p>Copyright: All articles except special statements are used <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">CC BY-NC-ND 4.0</a> license agreement, reproduced please indicate the source!</p></blockquote><hr></div></div></article><div class="blog-post-comments"><div id="tcomment"><noscript>Please enable JavaScript to view the comments.</noscript></div></div><div id="footer-post-container"><div id="footer-post"><div id="nav-footer" style="display:none"><ul><li><a href="/en">Home</a></li><li><a href="/en/tags">Tag</a></li><li><a href="/en/search">Search</a></li><li><a href="/en/tools">Tool</a></li><li><a href="/en/about">About</a></li></ul></div><div id="toc-footer" style="display:none"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#CUDA-driver"><span class="toc-number">1.</span> <span class="toc-text">CUDA driver</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Conda"><span class="toc-number">2.</span> <span class="toc-text">Conda</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pytorch"><span class="toc-number">3.</span> <span class="toc-text">Pytorch</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CUDA"><span class="toc-number">4.</span> <span class="toc-text">CUDA</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Cuda-installed-using-conda"><span class="toc-number">4.1.</span> <span class="toc-text">Cuda installed using conda</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Extra"><span class="toc-number">5.</span> <span class="toc-text">Extra</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#gcc-clang-g-clang"><span class="toc-number">5.1.</span> <span class="toc-text">gcc clang g++ clang++</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#xformers"><span class="toc-number">5.2.</span> <span class="toc-text">xformers</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#transformers-amp-datasets-amp-accelerate"><span class="toc-number">5.3.</span> <span class="toc-text">transformers &amp; datasets &amp; accelerate</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Reference"><span class="toc-number">6.</span> <span class="toc-text">Reference</span></a></li></ol></div><div id="actions-footer"><a id="menu" class="icon" onclick='$("#nav-footer").toggle()'><i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a> <a id="toc" class="icon" onclick='$("#toc-footer").toggle()'><i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a> <a id="switch" class="icon" onclick="switchNightMode()"><i class="fas fa-lightbulb fa-lg" aria-hidden="true"></i> Theme</a> <a id="top" style="display:none" class="icon" href="#" onclick='$("html, body").animate({scrollTop:0},"fast")'><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a></div></div></div><footer id="footer"><div class="footer-left">Copyright &copy; 2020-2024 Yuesir <a href="https://github.com/probberechts/hexo-theme-cactus" rel="nofollow" target="_blank">Cactus</a> <a href="/en/atom.xml" target="_blank">RSS</a></div><div class="footer-right"><nav><ul><li><a href="/en">Home</a></li><li><a href="/en/tags">Tag</a></li><li><a href="/en/search">Search</a></li><li><a href="/en/tools">Tool</a></li><li><a href="/en/about">About</a></li></ul></nav></div></footer></div><link rel="preload" href="/en/lib/font-awesome/css/all.min.css" as="style" onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel="stylesheet" href="/en/lib/font-awesome/css/all.min.css"></noscript><script src="/en/lib/jquery/jquery.min.js"></script><script src="/en/lib/clipboard/clipboard.min.js"></script><script type="text/javascript">$((function(){$(".highlight table").before('<span class="btn-copy tooltipped tooltipped-sw" aria-label="Copy to clipboard"><i class="far fa-clone"></i></span>'),new ClipboardJS(".btn-copy",{text:function(e){return Array.from(e.nextElementSibling.querySelectorAll(".code")).reduce((e,t)=>e+t.innerText+"\n","").replace(/^\s+|\s+$/g,"")}}).on("success",(function(e){e.trigger.setAttribute("aria-label","Copied!"),e.clearSelection()}))}))</script><script src="/en/js/main.js"></script><script src="/en/lib/fancybox/fancybox.umd.js"></script><script src="/en/lib/twikoo/twikoo.all.min.js"></script><script>twikoo.init({envId:"https://twikoo.vccv.cc",el:"#tcomment",lang:"en",onCommentLoaded:function(){for(var t=document.getElementsByClassName("tk-content"),e=0;e<t.length;e++){var n=t[e].getElementsByTagName("img");if(n.length>0)for(var a=0;a<n.length;a++){var o=n[a];if("tk-owo-emotion"!=o.className){var r=document.createElement("a");r.setAttribute("data-fancybox","gallery"),r.setAttribute("data-src",o.getAttribute("src")),r.setAttribute("data-caption","Comment: "+o.getAttribute("alt")),r.appendChild(o.cloneNode(!1)),o.parentNode.insertBefore(r,o.nextSibling),o.remove()}}}}})</script><script src="/lib/april-fool/load.js"></script></body></html>